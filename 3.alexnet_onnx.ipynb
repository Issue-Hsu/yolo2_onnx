{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: https://github.com/onnx/tutorials/blob/master/tutorials/PytorchOnnxExport.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save pre-trained model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "import torchvision\n",
    "\n",
    "# Standard ImageNet input - 3 channels, 224x224,\n",
    "# values don't matter as we care about network structure.\n",
    "# But they can also be real inputs.\n",
    "dummy_input = Variable(torch.randn(1, 3, 224, 224))\n",
    "# Obtain your model, it can be also constructed in your script explicitly\n",
    "model = torchvision.models.alexnet(pretrained=True)\n",
    "# Invoke export\n",
    "torch.onnx.export(model, dummy_input, \"alexnet.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model from ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %1[FLOAT, 1x3x224x224]\n",
      ") initializers (\n",
      "  %2[FLOAT, 64x3x11x11]\n",
      "  %3[FLOAT, 64]\n",
      "  %4[FLOAT, 192x64x5x5]\n",
      "  %5[FLOAT, 192]\n",
      "  %6[FLOAT, 384x192x3x3]\n",
      "  %7[FLOAT, 384]\n",
      "  %8[FLOAT, 256x384x3x3]\n",
      "  %9[FLOAT, 256]\n",
      "  %10[FLOAT, 256x256x3x3]\n",
      "  %11[FLOAT, 256]\n",
      "  %12[FLOAT, 4096x9216]\n",
      "  %13[FLOAT, 4096]\n",
      "  %14[FLOAT, 4096x4096]\n",
      "  %15[FLOAT, 4096]\n",
      "  %16[FLOAT, 1000x4096]\n",
      "  %17[FLOAT, 1000]\n",
      ") {\n",
      "  %19 = Conv[dilations = [1, 1], group = 1, kernel_shape = [11, 11], pads = [2, 2, 2, 2], strides = [4, 4]](%1, %2)\n",
      "  %20 = Add[axis = 1, broadcast = 1](%19, %3)\n",
      "  %21 = Relu(%20)\n",
      "  %22 = MaxPool[kernel_shape = [3, 3], pads = [0, 0], strides = [2, 2]](%21)\n",
      "  %24 = Conv[dilations = [1, 1], group = 1, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%22, %4)\n",
      "  %25 = Add[axis = 1, broadcast = 1](%24, %5)\n",
      "  %26 = Relu(%25)\n",
      "  %27 = MaxPool[kernel_shape = [3, 3], pads = [0, 0], strides = [2, 2]](%26)\n",
      "  %29 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%27, %6)\n",
      "  %30 = Add[axis = 1, broadcast = 1](%29, %7)\n",
      "  %31 = Relu(%30)\n",
      "  %33 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%31, %8)\n",
      "  %34 = Add[axis = 1, broadcast = 1](%33, %9)\n",
      "  %35 = Relu(%34)\n",
      "  %37 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%35, %10)\n",
      "  %38 = Add[axis = 1, broadcast = 1](%37, %11)\n",
      "  %39 = Relu(%38)\n",
      "  %40 = MaxPool[kernel_shape = [3, 3], pads = [0, 0], strides = [2, 2]](%39)\n",
      "  %41 = Reshape[shape = [1, 9216]](%40)\n",
      "  %43, %44 = Dropout[is_test = 1, ratio = 0.5](%41)\n",
      "  %47 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%43, %12, %13)\n",
      "  %48 = Relu(%47)\n",
      "  %50, %51 = Dropout[is_test = 1, ratio = 0.5](%48)\n",
      "  %54 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%50, %14, %15)\n",
      "  %55 = Relu(%54)\n",
      "  %58 = Gemm[alpha = 1, beta = 1, broadcast = 1, transB = 1](%55, %16, %17)\n",
      "  return %58\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"alexnet.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with your prefered toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import numpy as np\n",
    "imgfile = './data/dog.jpg'\n",
    "img = Image.open(imgfile).resize( (224, 224) )\n",
    "img_arr = np.array(img)\n",
    "img_arr = np.expand_dims(img_arr, -1)\n",
    "img_arr = np.transpose(img_arr, (3,2,0,1))\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"caffe2.python.workspace\"\n"
     ]
    }
   ],
   "source": [
    "import onnx_caffe2.backend as backend\n",
    "\n",
    "rep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\"\n",
    "outputs = rep.run(img_arr.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
