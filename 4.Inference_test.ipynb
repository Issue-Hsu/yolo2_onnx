{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Inference import Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  =  Inference(modelName=\"yolo2\",backend='tensorflow', device='CUDA:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference: Prepare model and backend...start\n",
      "Folder [onnx] has already exist!\n",
      "Weights file [./yolo.weights] has already exist!\n",
      "Loading weights from local [./yolo.weights]... start\n",
      "Loading weights from local [./yolo.weights]... done, 0.09 sec\n",
      "Dump pickle file of detection_information [yolo2_detection_information.pkl]...done\n",
      "Onnx file has already exist!\n",
      "Load onnx file [./onnx/yolo2.onnx]...start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cfg.py:175: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\n",
      "cfg.py:157: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w])); start = start + num_w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load onnx file [./onnx/yolo2.onnx]...done, 0.21 sec\n",
      "Prepare_backend with [tensorflow] using [CUDA:0]...start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python2.7/dist-packages/onnx_tf/backend.py:677: UserWarning: Unsupported kernel_shape attribute by Tensorflow in Conv operator. The attribute will be ignored.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare_backend [tensorflow] [CUDA:0]...done, 38.96 sec\n",
      "Inference: Prepare model and backend...end, 39.88 sec\n",
      "Inference: Inference...start\n",
      "Inference ...start\n",
      "Inference ... done!\n",
      "Inference: Inference...end, 3.21 sec\n",
      "Detect ...start\n",
      "save plot results to predictions.jpg\n",
      "Detect ... done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "utils.py:140: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  cls_confs = torch.nn.Softmax()(Variable(output[5:5+num_classes].transpose(0,1))).data\n"
     ]
    }
   ],
   "source": [
    "str_, time_cost = a.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prepare_time:39.88, inference_time:3.21'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck: 0.934710 \\nbicycle: 0.998012 \\ndog: 0.990524 \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference: Prepare model and backend...start\n",
      "Folder [onnx] has already exist!\n",
      "Weights file [./yolo.weights] has already exist!\n",
      "Loading weights from local [./yolo.weights]... start\n",
      "Loading weights from local [./yolo.weights]... done, 0.09 sec\n",
      "Dump pickle file of detection_information [yolo2_detection_information.pkl]...done\n",
      "Onnx file has already exist!\n",
      "Load onnx file [./onnx/yolo2.onnx]...start\n",
      "Load onnx file [./onnx/yolo2.onnx]...done, 0.18 sec\n",
      "Prepare_backend with [tensorflow] using [CPU]...start\n",
      "Prepare_backend [tensorflow] [CPU]...done, 38.23 sec\n",
      "Inference: Prepare model and backend...end, 38.98 sec\n",
      "Inference: Inference...start\n",
      "Inference ...start\n",
      "Inference ... done!\n",
      "Inference: Inference...end, 3.43 sec\n",
      "Detect ...start\n",
      "save plot results to predictions.jpg\n",
      "Detect ... done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'prepare_time:38.98, inference_time:3.43'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b  =  Inference(modelName=\"yolo2\",backend='tensorflow', device='CPU')\n",
    "str_, time_cost = b.predict()\n",
    "time_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference: Prepare model and backend...start\n",
      "Folder [onnx] has already exist!\n",
      "Onnx file has already exist!\n",
      "Load onnx file [./onnx/vgg19.onnx]...start\n",
      "Load onnx file [./onnx/vgg19.onnx]...done, 0.56 sec\n",
      "Prepare_backend with [tensorflow] using [CUDA:0]...start\n",
      "Prepare_backend [tensorflow] [CUDA:0]...done, 107.82 sec\n",
      "Inference: Prepare model and backend...end, 116.87 sec\n",
      "Inference: Inference...start\n",
      "Inference ...start\n",
      "Inference ... done!\n",
      "Inference: Inference...end, 9.47 sec\n",
      "('6.94% : Weimaraner \\n5.83% : whippet \\n5.69% : English setter \\n5.60% : West Highland white terrier \\n5.49% : tricycle, trike, velocipede \\n', 'prepare_time:116.87, inference_time:9.47')\n"
     ]
    }
   ],
   "source": [
    "b  =  Inference(modelName=\"vgg19\")\n",
    "print (b.predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
